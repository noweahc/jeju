{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaewon/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='AppleGothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/chaewon/Desktop/공모전/DACON_제주/data/train.csv')\n",
    "trade = pd.read_csv('/Users/chaewon/Desktop/공모전/DACON_제주/data/international_trade.csv')\n",
    "test = pd.read_csv('/Users/chaewon/Desktop/공모전/DACON_제주/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'supply(kg)': 'supply', 'price(원/kg)': 'price'})\n",
    "train.drop(columns=['ID'], inplace=True) \n",
    "test.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'item', 'corporation', 'location', 'supply', 'price',\n",
      "       'year', 'month', 'day', 'ismarch'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#연월일\n",
    "train['year'] = pd.to_datetime(train['timestamp']).dt.year\n",
    "train['month'] = pd.to_datetime(train['timestamp']).dt.month\n",
    "train['day'] = pd.to_datetime(train['timestamp']).dt.day\n",
    "train['ismarch'] = np.where(train['month'] == 3, 1, 0)\n",
    "\n",
    "\n",
    "print(train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'timestamp', 'item', 'corporation', 'location', 'year', 'month',\n",
      "       'day', 'ismarch'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test['year'] = pd.to_datetime(test['timestamp']).dt.year\n",
    "test['month'] = pd.to_datetime(test['timestamp']).dt.month\n",
    "test['day'] = pd.to_datetime(test['timestamp']).dt.day\n",
    "test['ismarch'] = np.where(test['month'] == 3, 1, 0)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp item corporation location        supply        price  year  \\\n",
      "0  2019-01-01   TG           A        J  39655.713419  1588.269032  2019   \n",
      "1  2019-01-02   TG           A        J  39681.297751  1589.293722  2019   \n",
      "2  2019-01-03   TG           A        J  60601.000000  1728.000000  2019   \n",
      "3  2019-01-04   TG           A        J  25000.000000  1408.000000  2019   \n",
      "4  2019-01-05   TG           A        J  32352.000000  1250.000000  2019   \n",
      "\n",
      "   month  day  ismarch  \n",
      "0      1    1        0  \n",
      "1      1    2        0  \n",
      "2      1    3        0  \n",
      "3      1    4        0  \n",
      "4      1    5        0  \n"
     ]
    }
   ],
   "source": [
    "# 'price'와 'supply'가 0인 행을 해당 'item' 종목 및 'month' 별 평균값으로 대체\n",
    "for index, row in train[(train['price'] == 0)].iterrows():\n",
    "    item = row['item']\n",
    "    month = row['month']\n",
    "    \n",
    "    # 해당 'item' 및 'month'에 대한 평균값 계산\n",
    "    avg_price = train[(train['item'] == item) & (train['month'] == month)]['price'].mean()\n",
    "    avg_supply = train[(train['item'] == item) & (train['month'] == month)]['supply'].mean()\n",
    "    \n",
    "    # 대체\n",
    "    train.at[index, 'price'] = avg_price\n",
    "    train.at[index, 'supply'] = avg_supply\n",
    "\n",
    "# 변경된 'train' 데이터프레임 확인\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'train' 데이터프레임에 'month' 및 'item' 별 'supply' 평균 계산\n",
    "mean_supply_by_month_item = train.groupby(['month', 'item'])['supply'].mean()\n",
    "\n",
    "# 'test' 데이터프레임에 'month' 및 'item'을 기준으로 'supply' 평균값을 병합 (merge)\n",
    "test_merged = pd.merge(test, mean_supply_by_month_item.reset_index(), on=['month', 'item'], how='left')\n",
    "\n",
    "# 'supply_y' 열은 평균값을 의미하므로, 'supply_y' 열을 'supply'로 이름 변경\n",
    "test_merged.rename(columns={'supply_y': 'supply'}, inplace=True)\n",
    "\n",
    "# 'supply_x' 열은 병합 전 'test' 데이터프레임에 있던 열이므로 삭제\n",
    "#test_merged.drop('supply_x', axis=1, inplace=True)\n",
    "\n",
    "# 'test' 데이터프레임에 적용된 수정 사항을 확인\n",
    "test = test_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(train, columns=['item', 'corporation', 'location'])\n",
    "df_encoded.drop(columns=['timestamp'], inplace=True)\n",
    "train= df_encoded\n",
    "\n",
    "test.drop(columns=['timestamp'], inplace=True)\n",
    "df_encoded2 = pd.get_dummies(test, columns=['item','corporation', 'location'])\n",
    "test= df_encoded2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(by=['year', 'month', 'day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['year', 'month', 'day','supply', 'item_BC', 'item_CB',\n",
    "       'item_CR', 'item_RD', 'item_TG', 'corporation_A', 'corporation_B',\n",
    "       'corporation_C', 'corporation_D', 'corporation_E', 'corporation_F',\n",
    "       'location_J', 'location_S','ismarch']]\n",
    "y_train = train['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.reshape(y_train, (len(y_train), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1857/1857 [==============================] - 2s 655us/step - loss: 0.0012\n",
      "Epoch 2/70\n",
      "1857/1857 [==============================] - 1s 592us/step - loss: 0.0014\n",
      "Epoch 3/70\n",
      "1857/1857 [==============================] - 1s 593us/step - loss: 0.0017\n",
      "Epoch 4/70\n",
      "1857/1857 [==============================] - 1s 590us/step - loss: 0.0019\n",
      "Epoch 5/70\n",
      "1857/1857 [==============================] - 1s 592us/step - loss: 0.0020\n",
      "Epoch 6/70\n",
      "1857/1857 [==============================] - 1s 591us/step - loss: 0.0020\n",
      "Epoch 7/70\n",
      "1857/1857 [==============================] - 1s 591us/step - loss: 0.0020\n",
      "Epoch 8/70\n",
      "1857/1857 [==============================] - 1s 587us/step - loss: 0.0020\n",
      "Epoch 9/70\n",
      "1857/1857 [==============================] - 1s 598us/step - loss: 0.0020\n",
      "Epoch 10/70\n",
      "1857/1857 [==============================] - 1s 586us/step - loss: 0.0019\n",
      "Epoch 11/70\n",
      "1857/1857 [==============================] - 1s 594us/step - loss: 0.0017\n",
      "Epoch 12/70\n",
      "1857/1857 [==============================] - 1s 589us/step - loss: 0.0015\n",
      "Epoch 13/70\n",
      "1857/1857 [==============================] - 1s 607us/step - loss: 0.0014\n",
      "Epoch 14/70\n",
      "1857/1857 [==============================] - 1s 602us/step - loss: 0.0014\n",
      "Epoch 15/70\n",
      "1857/1857 [==============================] - 1s 589us/step - loss: 0.0014\n",
      "Epoch 16/70\n",
      "1857/1857 [==============================] - 1s 593us/step - loss: 0.0014\n",
      "Epoch 17/70\n",
      "1857/1857 [==============================] - 1s 595us/step - loss: 0.0014\n",
      "Epoch 18/70\n",
      "1857/1857 [==============================] - 1s 591us/step - loss: 0.0013\n",
      "Epoch 19/70\n",
      "1857/1857 [==============================] - 1s 588us/step - loss: 0.0013\n",
      "Epoch 20/70\n",
      "1857/1857 [==============================] - 1s 596us/step - loss: 0.0013\n",
      "Epoch 21/70\n",
      "1857/1857 [==============================] - 1s 590us/step - loss: 0.0013\n",
      "Epoch 22/70\n",
      "1857/1857 [==============================] - 1s 589us/step - loss: 0.0013\n",
      "Epoch 23/70\n",
      "1857/1857 [==============================] - 1s 607us/step - loss: 0.0012\n",
      "Epoch 24/70\n",
      "1857/1857 [==============================] - 1s 594us/step - loss: 0.0012\n",
      "Epoch 25/70\n",
      "1857/1857 [==============================] - 1s 600us/step - loss: 0.0012\n",
      "Epoch 26/70\n",
      "1857/1857 [==============================] - 1s 594us/step - loss: 0.0012\n",
      "Epoch 27/70\n",
      "1857/1857 [==============================] - 1s 589us/step - loss: 0.0012\n",
      "Epoch 28/70\n",
      "1857/1857 [==============================] - 1s 587us/step - loss: 0.0012\n",
      "Epoch 29/70\n",
      "1857/1857 [==============================] - 1s 591us/step - loss: 0.0012\n",
      "Epoch 30/70\n",
      "1857/1857 [==============================] - 1s 598us/step - loss: 0.0012\n",
      "Epoch 31/70\n",
      "1857/1857 [==============================] - 1s 614us/step - loss: 0.0012\n",
      "Epoch 32/70\n",
      "1857/1857 [==============================] - 1s 586us/step - loss: 0.0012\n",
      "Epoch 33/70\n",
      "1857/1857 [==============================] - 1s 588us/step - loss: 0.0012\n",
      "Epoch 34/70\n",
      "1857/1857 [==============================] - 1s 592us/step - loss: 0.0012\n",
      "Epoch 35/70\n",
      "1857/1857 [==============================] - 1s 587us/step - loss: 0.0011\n",
      "Epoch 36/70\n",
      "1857/1857 [==============================] - 1s 588us/step - loss: 0.0011\n",
      "Epoch 37/70\n",
      "1857/1857 [==============================] - 1s 590us/step - loss: 0.0011\n",
      "Epoch 38/70\n",
      "1857/1857 [==============================] - 1s 588us/step - loss: 0.0011\n",
      "Epoch 39/70\n",
      "1857/1857 [==============================] - 1s 586us/step - loss: 0.0011\n",
      "Epoch 40/70\n",
      "1857/1857 [==============================] - 1s 594us/step - loss: 0.0011\n",
      "Epoch 41/70\n",
      "1857/1857 [==============================] - 1s 648us/step - loss: 0.0011\n",
      "Epoch 42/70\n",
      "1857/1857 [==============================] - 1s 634us/step - loss: 0.0011\n",
      "Epoch 43/70\n",
      "1857/1857 [==============================] - 1s 651us/step - loss: 0.0011\n",
      "Epoch 44/70\n",
      "1857/1857 [==============================] - 1s 621us/step - loss: 0.0011\n",
      "Epoch 45/70\n",
      "1857/1857 [==============================] - 1s 641us/step - loss: 0.0011\n",
      "Epoch 46/70\n",
      "1857/1857 [==============================] - 1s 604us/step - loss: 0.0011\n",
      "Epoch 47/70\n",
      "1857/1857 [==============================] - 1s 603us/step - loss: 0.0011\n",
      "Epoch 48/70\n",
      "1857/1857 [==============================] - 1s 634us/step - loss: 0.0011\n",
      "Epoch 49/70\n",
      "1857/1857 [==============================] - 1s 617us/step - loss: 0.0011\n",
      "Epoch 50/70\n",
      "1857/1857 [==============================] - 1s 627us/step - loss: 0.0011\n",
      "Epoch 51/70\n",
      "1857/1857 [==============================] - 1s 646us/step - loss: 0.0011\n",
      "Epoch 52/70\n",
      "1857/1857 [==============================] - 1s 647us/step - loss: 0.0011\n",
      "Epoch 53/70\n",
      "1857/1857 [==============================] - 1s 625us/step - loss: 0.0011\n",
      "Epoch 54/70\n",
      "1857/1857 [==============================] - 1s 627us/step - loss: 0.0011\n",
      "Epoch 55/70\n",
      "1857/1857 [==============================] - 1s 599us/step - loss: 0.0011\n",
      "Epoch 56/70\n",
      "1857/1857 [==============================] - 1s 595us/step - loss: 0.0011\n",
      "Epoch 57/70\n",
      "1857/1857 [==============================] - 1s 613us/step - loss: 0.0011\n",
      "Epoch 58/70\n",
      "1857/1857 [==============================] - 1s 602us/step - loss: 0.0011\n",
      "Epoch 59/70\n",
      "1857/1857 [==============================] - 1s 591us/step - loss: 0.0011\n",
      "Epoch 60/70\n",
      "1857/1857 [==============================] - 1s 590us/step - loss: 0.0011\n",
      "Epoch 61/70\n",
      "1857/1857 [==============================] - 1s 584us/step - loss: 0.0011\n",
      "Epoch 62/70\n",
      "1857/1857 [==============================] - 1s 593us/step - loss: 0.0011\n",
      "Epoch 63/70\n",
      "1857/1857 [==============================] - 1s 607us/step - loss: 0.0011\n",
      "Epoch 64/70\n",
      "1857/1857 [==============================] - 1s 589us/step - loss: 0.0011\n",
      "Epoch 65/70\n",
      "1857/1857 [==============================] - 1s 587us/step - loss: 0.0011\n",
      "Epoch 66/70\n",
      "1857/1857 [==============================] - 1s 615us/step - loss: 0.0011\n",
      "Epoch 67/70\n",
      "1857/1857 [==============================] - 1s 590us/step - loss: 0.0011\n",
      "Epoch 68/70\n",
      "1857/1857 [==============================] - 1s 590us/step - loss: 0.0011\n",
      "Epoch 69/70\n",
      "1857/1857 [==============================] - 1s 593us/step - loss: 0.0010\n",
      "Epoch 70/70\n",
      "1857/1857 [==============================] - 1s 617us/step - loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ce9132b0>"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler_X = MinMaxScaler()\n",
    "normalized_X_train = scaler_X.fit_transform(X_train)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "normalized_y_train = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "# LSTM에 입력으로 넣기 위한 형태로 변환\n",
    "# (샘플 수, 타임 스텝 수, 특성 수)\n",
    "# 여기서는 간단하게 타임 스텝을 1로 설정합니다.\n",
    "X_train_reshaped = normalized_X_train.reshape((normalized_X_train.shape[0], 1, normalized_X_train.shape[1]))\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_reshaped, normalized_y_train, epochs=70, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 363us/step\n",
      "[[3228.4966]\n",
      " [3313.3066]\n",
      " [3398.351 ]\n",
      " ...\n",
      " [1282.1215]\n",
      " [1300.9712]\n",
      " [1319.0067]]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 데이터에 대한 예측\n",
    "# (예측값을 다시 역정규화하여 원래 스케일로 되돌릴 수 있습니다.)\n",
    "new_data = test\n",
    "# 'train' 데이터프레임에서 사용한 feature들의 순서를 가져옴\n",
    "train_feature_order = X_train.columns.tolist()\n",
    "\n",
    "# 'new_data'에서 사용한 feature들의 순서를 가져옴\n",
    "new_data_feature_order = new_data.columns.tolist()\n",
    "\n",
    "# 'new_data'를 'train' 데이터프레임의 feature 순서에 맞게 재정렬\n",
    "new_data_reordered = new_data[train_feature_order]\n",
    "\n",
    "# 'scaler_X'를 다시 초기화하여 'new_data_reordered'를 변환\n",
    "new_data_scaled = scaler_X.transform(new_data_reordered)\n",
    "# 새로운 데이터도 정규화\n",
    "new_data_reshaped = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
    "\n",
    "predicted_scaled = model.predict(new_data_reshaped)\n",
    "\n",
    "# 예측 결과 역정규화\n",
    "predicted = scaler_y.inverse_transform(predicted_scaled)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = submission = pd.read_csv('/Users/chaewon/Desktop/공모전/DACON_제주/data/sample_submission.csv')\n",
    "submission['answer'] = predicted\n",
    "submission.to_csv('submission_lstm_pepero2.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
